{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7251931,"sourceType":"datasetVersion","datasetId":4201757},{"sourceId":7252210,"sourceType":"datasetVersion","datasetId":4201942},{"sourceId":7252276,"sourceType":"datasetVersion","datasetId":4201990},{"sourceId":7253448,"sourceType":"datasetVersion","datasetId":4202836},{"sourceId":5111,"sourceType":"modelInstanceVersion","modelInstanceId":3899}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -Uqqq pip --progress-bar off\n!pip install -qqq peft==0.5.0 --progress-bar off\n!pip install -qqq bitsandbytes==0.41.1 --progress-bar off\n!pip install -qqq trl==0.7.1 --progress-bar off\n!pip install einops\n!pip install -qqq datasets==2.15.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-21T06:03:20.779171Z","iopub.execute_input":"2023-12-21T06:03:20.779626Z","iopub.status.idle":"2023-12-21T06:04:46.372517Z","shell.execute_reply.started":"2023-12-21T06:03:20.7796Z","shell.execute_reply":"2023-12-21T06:04:46.371411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport re\nfrom pprint import pprint\nimport pandas as pd\nimport torch\nfrom datasets import Dataset, load_dataset\nfrom huggingface_hub import notebook_login\nfrom peft import LoraConfig, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline\n)\nfrom trl import SFTTrainer\n\nDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nMODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:06:01.691183Z","iopub.execute_input":"2023-12-21T06:06:01.691609Z","iopub.status.idle":"2023-12-21T06:06:17.835967Z","shell.execute_reply.started":"2023-12-21T06:06:01.691576Z","shell.execute_reply":"2023-12-21T06:06:17.835187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:06:52.425151Z","iopub.execute_input":"2023-12-21T06:06:52.426171Z","iopub.status.idle":"2023-12-21T06:06:52.447918Z","shell.execute_reply.started":"2023-12-21T06:06:52.426137Z","shell.execute_reply":"2023-12-21T06:06:52.446963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_and_tokenizer():\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.float16,\n    )\n\n    model = AutoModelForCausalLM.from_pretrained(\n        MODEL_NAME,\n        quantization_config=bnb_config,\n        trust_remote_code=True,\n        device_map=\"auto\",\n    )\n\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.padding_side = \"right\"\n\n    return model, tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:07:01.31806Z","iopub.execute_input":"2023-12-21T06:07:01.318936Z","iopub.status.idle":"2023-12-21T06:07:01.324588Z","shell.execute_reply.started":"2023-12-21T06:07:01.318902Z","shell.execute_reply":"2023-12-21T06:07:01.323543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = create_model_and_tokenizer()\nmodel.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:07:17.687276Z","iopub.execute_input":"2023-12-21T06:07:17.687663Z","iopub.status.idle":"2023-12-21T06:09:32.384441Z","shell.execute_reply.started":"2023-12-21T06:07:17.687633Z","shell.execute_reply":"2023-12-21T06:09:32.383693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.quantization_config.to_dict()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:09:32.38633Z","iopub.execute_input":"2023-12-21T06:09:32.387151Z","iopub.status.idle":"2023-12-21T06:09:32.394155Z","shell.execute_reply.started":"2023-12-21T06:09:32.387114Z","shell.execute_reply":"2023-12-21T06:09:32.393239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_r = 16\nlora_alpha = 64\nlora_dropout = 0.1\nlora_target_modules = [\n    \"q_proj\",\n    \"up_proj\",\n    \"o_proj\",\n    \"k_proj\",\n    \"down_proj\",\n    \"gate_proj\",\n    \"v_proj\",\n]\n\n\npeft_config = LoraConfig(\n    r=lora_r,\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    target_modules=lora_target_modules,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset('chienpham/vnpara_train')\ndataset = dataset['train'].train_test_split(test_size = 0.1)\ndataset['validation'] = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:13:45.033894Z","iopub.execute_input":"2023-12-21T06:13:45.034233Z","iopub.status.idle":"2023-12-21T06:13:46.685901Z","shell.execute_reply.started":"2023-12-21T06:13:45.034208Z","shell.execute_reply":"2023-12-21T06:13:46.684947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEFAULT_SYSTEM_PROMPT = \"\"\"\nEvaluate the semantic similarity of these two sentences, answer with only one character: 0 means the two sentences has different meaning, 1 means the two sentences has the same meaning.\n\"\"\".strip()\n\n\ndef generate_training_prompt(\n    s1: str, s2:str, lbl: int, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n) -> str:\n    s = 'Yes.' if lbl == 1 else 'No.'\n    return f\"\"\"### Question: Do these two sentences have the same meaning? \nSentence 1: {s1}\nSentence 2: {s2}\nAnswer \"Yes\" or \"No\".\n\n### Answer:\n{s}\n\"\"\"\ndef generate_text(row):\n    s1 = row['sentence1']\n    s2 = row['sentence2']\n    label = row['label']\n    return {\n        \"text\": generate_training_prompt(s1, s2, label),\n    }\ndef process_dataset(data: Dataset):\n    return (\n        data.shuffle(seed=42)\n        .map(generate_text)\n        .remove_columns(\n            [\n                \"sentence1\",\n                \"sentence2\",\n                \"label\"\n            ]\n        )\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\", \n    model=model, \n    tokenizer = tokenizer, \n    torch_dtype=torch.bfloat16, \n    device_map=\"auto\"\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-21T05:18:15.142783Z","iopub.execute_input":"2023-12-21T05:18:15.143152Z","iopub.status.idle":"2023-12-21T05:19:16.911791Z","shell.execute_reply.started":"2023-12-21T05:18:15.143117Z","shell.execute_reply":"2023-12-21T05:19:16.910795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"\"\"\nEvaluate the semantic similarity of these two sentences, answer with only one character: 0 means the two sentences has different meaning, 1 means the two sentences has the same meaning.\nSentence 1: Hacker còn tuyên bố \" sẽ dòm ngó các trung tâm và công ty bảo mật \" khác.\nSentence 2: Thông điệp nhóm hacker này để lại là: \"Chúng tôi sẽ dòm ngó các trung tâm và công ty bảo mật\".\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-21T05:23:40.096663Z","iopub.execute_input":"2023-12-21T05:23:40.097373Z","iopub.status.idle":"2023-12-21T05:23:40.101646Z","shell.execute_reply.started":"2023-12-21T05:23:40.097342Z","shell.execute_reply":"2023-12-21T05:23:40.100702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_dataset(data: Dataset):\n    return (\n        data.shuffle(seed=42)\n        .map(generate_text)\n        .remove_columns(\n            [\n                \"sentence1\",\n                \"sentence2\",\n                \"label\"\n            ]\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:04:12.197004Z","iopub.execute_input":"2023-12-19T12:04:12.197399Z","iopub.status.idle":"2023-12-19T12:04:12.202146Z","shell.execute_reply.started":"2023-12-19T12:04:12.197368Z","shell.execute_reply":"2023-12-19T12:04:12.201414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[\"train\"] = process_dataset(dataset[\"train\"])\ndataset[\"validation\"] = process_dataset(dataset[\"validation\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:14:37.435833Z","iopub.execute_input":"2023-12-21T06:14:37.436234Z","iopub.status.idle":"2023-12-21T06:14:37.454453Z","shell.execute_reply.started":"2023-12-21T06:14:37.436204Z","shell.execute_reply":"2023-12-21T06:14:37.453659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:14:40.64994Z","iopub.execute_input":"2023-12-21T06:14:40.650316Z","iopub.status.idle":"2023-12-21T06:14:40.656306Z","shell.execute_reply.started":"2023-12-21T06:14:40.650287Z","shell.execute_reply":"2023-12-21T06:14:40.655404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_DIR = \"experiments\"\ntraining_arguments = TrainingArguments(\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_32bit\",\n    logging_steps=1,\n    learning_rate=1e-4,\n    fp16=True,\n    max_grad_norm=0.3,\n    num_train_epochs=2,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    warmup_ratio=0.05,\n    save_strategy=\"epoch\",\n    group_by_length=True,\n    output_dir=OUTPUT_DIR,\n    report_to=\"tensorboard\",\n    save_safetensors=True,\n    lr_scheduler_type=\"cosine\",\n    seed=42,\n)\n\nlora_r = 16\nlora_alpha = 64\nlora_dropout = 0.1\nlora_target_modules = [\n    \"q_proj\",\n    \"up_proj\",\n    \"o_proj\",\n    \"k_proj\",\n    \"down_proj\",\n    \"gate_proj\",\n    \"v_proj\",\n]\n\n\npeft_config = LoraConfig(\n    r=lora_r,\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    target_modules=lora_target_modules,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:14:58.087631Z","iopub.execute_input":"2023-12-21T06:14:58.088326Z","iopub.status.idle":"2023-12-21T06:14:58.097613Z","shell.execute_reply.started":"2023-12-21T06:14:58.088293Z","shell.execute_reply":"2023-12-21T06:14:58.096726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"validation\"],\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=4096,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:15:13.90585Z","iopub.execute_input":"2023-12-21T06:15:13.906715Z","iopub.status.idle":"2023-12-21T06:16:13.107469Z","shell.execute_reply.started":"2023-12-21T06:15:13.906671Z","shell.execute_reply":"2023-12-21T06:16:13.106716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T06:16:13.108911Z","iopub.execute_input":"2023-12-21T06:16:13.109166Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\nmodel_to_save.save_pretrained(\"outputs\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T09:04:51.914243Z","iopub.execute_input":"2023-12-21T09:04:51.91472Z","iopub.status.idle":"2023-12-21T09:04:52.209222Z","shell.execute_reply.started":"2023-12-21T09:04:51.914685Z","shell.execute_reply":"2023-12-21T09:04:52.208225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_model\nlora_config = LoraConfig.from_pretrained('outputs')\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T09:04:58.866525Z","iopub.execute_input":"2023-12-21T09:04:58.867193Z","iopub.status.idle":"2023-12-21T09:04:59.524Z","shell.execute_reply.started":"2023-12-21T09:04:58.867161Z","shell.execute_reply":"2023-12-21T09:04:59.523108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(\"Oillim/Mistral-7b-vnpara\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T09:05:20.875493Z","iopub.execute_input":"2023-12-21T09:05:20.876438Z","iopub.status.idle":"2023-12-21T09:05:31.30296Z","shell.execute_reply.started":"2023-12-21T09:05:20.876397Z","shell.execute_reply":"2023-12-21T09:05:31.301915Z"},"trusted":true},"execution_count":null,"outputs":[]}]}